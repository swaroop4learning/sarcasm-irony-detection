{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data procenotebookb022d1b41fssing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-10-27T08:27:09.265544Z","iopub.execute_input":"2023-10-27T08:27:09.266436Z","iopub.status.idle":"2023-10-27T08:27:09.624808Z","shell.execute_reply.started":"2023-10-27T08:27:09.266399Z","shell.execute_reply":"2023-10-27T08:27:09.623830Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"/kaggle/input/sarcasm/train-balanced-sarc.csv.gz\n/kaggle/input/sarcasm/train-balanced-sarcasm.csv\n/kaggle/input/sarcasm/test-balanced.csv\n/kaggle/input/sarcasm/test-unbalanced.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install setfit","metadata":{"execution":{"iopub.status.busy":"2023-10-27T08:27:09.626715Z","iopub.execute_input":"2023-10-27T08:27:09.627208Z","iopub.status.idle":"2023-10-27T08:27:26.446228Z","shell.execute_reply.started":"2023-10-27T08:27:09.627172Z","shell.execute_reply":"2023-10-27T08:27:26.445203Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Collecting setfit\n  Downloading setfit-0.7.0-py3-none-any.whl (45 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.9/45.9 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting datasets>=2.3.0 (from setfit)\n  Downloading datasets-2.14.6-py3-none-any.whl (493 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m493.7/493.7 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hCollecting sentence-transformers>=2.2.1 (from setfit)\n  Downloading sentence-transformers-2.2.2.tar.gz (85 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.0/86.0 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hCollecting evaluate>=0.3.0 (from setfit)\n  Downloading evaluate-0.4.1-py3-none-any.whl (84 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from datasets>=2.3.0->setfit) (1.23.5)\nRequirement already satisfied: pyarrow>=8.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets>=2.3.0->setfit) (11.0.0)\nRequirement already satisfied: dill<0.3.8,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets>=2.3.0->setfit) (0.3.7)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets>=2.3.0->setfit) (2.0.2)\nRequirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.10/site-packages (from datasets>=2.3.0->setfit) (2.31.0)\nRequirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.10/site-packages (from datasets>=2.3.0->setfit) (4.66.1)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets>=2.3.0->setfit) (3.3.0)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets>=2.3.0->setfit) (0.70.15)\nRequirement already satisfied: fsspec[http]<=2023.10.0,>=2023.1.0 in /opt/conda/lib/python3.10/site-packages (from datasets>=2.3.0->setfit) (2023.9.0)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets>=2.3.0->setfit) (3.8.4)\nRequirement already satisfied: huggingface-hub<1.0.0,>=0.14.0 in /opt/conda/lib/python3.10/site-packages (from datasets>=2.3.0->setfit) (0.16.4)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from datasets>=2.3.0->setfit) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from datasets>=2.3.0->setfit) (6.0)\nRequirement already satisfied: responses<0.19 in /opt/conda/lib/python3.10/site-packages (from evaluate>=0.3.0->setfit) (0.18.0)\nRequirement already satisfied: transformers<5.0.0,>=4.6.0 in /opt/conda/lib/python3.10/site-packages (from sentence-transformers>=2.2.1->setfit) (4.33.0)\nRequirement already satisfied: torch>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from sentence-transformers>=2.2.1->setfit) (2.0.0)\nRequirement already satisfied: torchvision in /opt/conda/lib/python3.10/site-packages (from sentence-transformers>=2.2.1->setfit) (0.15.1)\nRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (from sentence-transformers>=2.2.1->setfit) (1.2.2)\nRequirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from sentence-transformers>=2.2.1->setfit) (1.11.2)\nRequirement already satisfied: nltk in /opt/conda/lib/python3.10/site-packages (from sentence-transformers>=2.2.1->setfit) (3.2.4)\nRequirement already satisfied: sentencepiece in /opt/conda/lib/python3.10/site-packages (from sentence-transformers>=2.2.1->setfit) (0.1.99)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.3.0->setfit) (23.1.0)\nRequirement already satisfied: charset-normalizer<4.0,>=2.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.3.0->setfit) (3.1.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.3.0->setfit) (6.0.4)\nRequirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.3.0->setfit) (4.0.2)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.3.0->setfit) (1.9.2)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.3.0->setfit) (1.3.3)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.3.0->setfit) (1.3.1)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets>=2.3.0->setfit) (3.12.2)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets>=2.3.0->setfit) (4.6.3)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->datasets>=2.3.0->setfit) (3.0.9)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets>=2.3.0->setfit) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets>=2.3.0->setfit) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets>=2.3.0->setfit) (2023.7.22)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.6.0->sentence-transformers>=2.2.1->setfit) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.6.0->sentence-transformers>=2.2.1->setfit) (3.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.6.0->sentence-transformers>=2.2.1->setfit) (3.1.2)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers>=2.2.1->setfit) (2023.6.3)\nRequirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers>=2.2.1->setfit) (0.13.3)\nRequirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers>=2.2.1->setfit) (0.3.3)\nRequirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from nltk->sentence-transformers>=2.2.1->setfit) (1.16.0)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets>=2.3.0->setfit) (2.8.2)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets>=2.3.0->setfit) (2023.3)\nRequirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets>=2.3.0->setfit) (2023.3)\nRequirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->sentence-transformers>=2.2.1->setfit) (1.3.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->sentence-transformers>=2.2.1->setfit) (3.1.0)\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.10/site-packages (from torchvision->sentence-transformers>=2.2.1->setfit) (9.5.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.6.0->sentence-transformers>=2.2.1->setfit) (2.1.3)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.6.0->sentence-transformers>=2.2.1->setfit) (1.3.0)\nBuilding wheels for collected packages: sentence-transformers\n  Building wheel for sentence-transformers (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for sentence-transformers: filename=sentence_transformers-2.2.2-py3-none-any.whl size=125926 sha256=eea3eeec0ed994355f39aa1bbb499da4d91e32ef9f27bc694681dbe4d25a4265\n  Stored in directory: /root/.cache/pip/wheels/62/f2/10/1e606fd5f02395388f74e7462910fe851042f97238cbbd902f\nSuccessfully built sentence-transformers\nInstalling collected packages: sentence-transformers, datasets, evaluate, setfit\n  Attempting uninstall: datasets\n    Found existing installation: datasets 2.1.0\n    Uninstalling datasets-2.1.0:\n      Successfully uninstalled datasets-2.1.0\nSuccessfully installed datasets-2.14.6 evaluate-0.4.1 sentence-transformers-2.2.2 setfit-0.7.0\n","output_type":"stream"}]},{"cell_type":"code","source":"# Data processing\nimport pandas as pd\nimport numpy as np\n\n# Modeling\nimport tensorflow as tf\n\n# Hugging Face Dataset\nfrom datasets import Dataset\n\n# Model performance evaluation\n# import evaluate","metadata":{"execution":{"iopub.status.busy":"2023-10-27T08:27:26.447561Z","iopub.execute_input":"2023-10-27T08:27:26.447850Z","iopub.status.idle":"2023-10-27T08:27:34.469075Z","shell.execute_reply.started":"2023-10-27T08:27:26.447820Z","shell.execute_reply":"2023-10-27T08:27:34.468128Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"}]},{"cell_type":"code","source":"import csv\n\n# Define the CSV file path\ncsv_file = '/kaggle/input/sarcasm/train-balanced-sarcasm.csv'\n\n# Initialize an empty list to store the data\ndata = []\n\n# Open the CSV file\nwith open(csv_file, mode='r', newline='') as file:\n    # Create a CSV reader\n    reader = csv.reader(file)\n\n    # Skip the header row if it exists (optional)\n    header = next(reader)\n\n    # Iterate over the rows in the CSV file\n    for row in reader:\n        # Check if the value of the \"subreddit\" column is \"politics\"\n        if row[3] == 'politics':\n            # If it is, add the first two columns to the data list\n            data.append(row[:2])","metadata":{"execution":{"iopub.status.busy":"2023-10-27T08:27:34.471211Z","iopub.execute_input":"2023-10-27T08:27:34.471768Z","iopub.status.idle":"2023-10-27T08:27:39.568177Z","shell.execute_reply.started":"2023-10-27T08:27:34.471739Z","shell.execute_reply":"2023-10-27T08:27:39.567361Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"len(data)","metadata":{"execution":{"iopub.status.busy":"2023-10-27T08:27:39.570422Z","iopub.execute_input":"2023-10-27T08:27:39.571263Z","iopub.status.idle":"2023-10-27T08:27:39.578243Z","shell.execute_reply.started":"2023-10-27T08:27:39.571224Z","shell.execute_reply":"2023-10-27T08:27:39.577224Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"39496"},"metadata":{}}]},{"cell_type":"code","source":"data = pd.DataFrame(data)\n# Assuming 'data_test' is your DataFrame\ndata = data.rename(columns={0: 'label', 1: 'headline'})","metadata":{"execution":{"iopub.status.busy":"2023-10-27T08:27:39.579639Z","iopub.execute_input":"2023-10-27T08:27:39.579976Z","iopub.status.idle":"2023-10-27T08:27:39.603874Z","shell.execute_reply.started":"2023-10-27T08:27:39.579943Z","shell.execute_reply":"2023-10-27T08:27:39.603118Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"data [0:3]","metadata":{"execution":{"iopub.status.busy":"2023-10-27T08:27:39.604897Z","iopub.execute_input":"2023-10-27T08:27:39.605156Z","iopub.status.idle":"2023-10-27T08:27:39.621741Z","shell.execute_reply.started":"2023-10-27T08:27:39.605133Z","shell.execute_reply":"2023-10-27T08:27:39.620711Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"  label                                           headline\n0     0                                         NC and NH.\n1     0  I think a significant amount would be against ...\n2     0  because it's what really bothers him... and it...","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>label</th>\n      <th>headline</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>NC and NH.</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>I think a significant amount would be against ...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>because it's what really bothers him... and it...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# Convert the DataFrame to a list of dictionaries\ndata_list = data.to_dict(orient='records')\n\n# Rename the 'headline' key to 'sentence' to match your desired format\nfor item in data_list:\n    item['sentence'] = item.pop('headline')","metadata":{"execution":{"iopub.status.busy":"2023-10-27T08:27:39.622799Z","iopub.execute_input":"2023-10-27T08:27:39.623078Z","iopub.status.idle":"2023-10-27T08:27:39.794012Z","shell.execute_reply.started":"2023-10-27T08:27:39.623055Z","shell.execute_reply":"2023-10-27T08:27:39.793051Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"# Convert 'label' to integers and add 'idx' to each dictionary\nfor idx, data in enumerate(data_list):\n    data['label'] = int(data['label'])\n    data['idx'] = idx","metadata":{"execution":{"iopub.status.busy":"2023-10-27T08:27:39.795206Z","iopub.execute_input":"2023-10-27T08:27:39.795465Z","iopub.status.idle":"2023-10-27T08:27:39.822868Z","shell.execute_reply.started":"2023-10-27T08:27:39.795442Z","shell.execute_reply":"2023-10-27T08:27:39.822074Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\n# Split the data into training (80%) and testing (20%)\ntrain_data, test_data = train_test_split(data_list, test_size=0.2, random_state=42)\n","metadata":{"execution":{"iopub.status.busy":"2023-10-27T08:27:39.826783Z","iopub.execute_input":"2023-10-27T08:27:39.827139Z","iopub.status.idle":"2023-10-27T08:27:40.193410Z","shell.execute_reply.started":"2023-10-27T08:27:39.827107Z","shell.execute_reply":"2023-10-27T08:27:40.192298Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"len(train_data)","metadata":{"execution":{"iopub.status.busy":"2023-10-27T08:27:40.194681Z","iopub.execute_input":"2023-10-27T08:27:40.195001Z","iopub.status.idle":"2023-10-27T08:27:40.201191Z","shell.execute_reply.started":"2023-10-27T08:27:40.194973Z","shell.execute_reply":"2023-10-27T08:27:40.200237Z"},"trusted":true},"execution_count":12,"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"31596"},"metadata":{}}]},{"cell_type":"code","source":"len(test_data)","metadata":{"execution":{"iopub.status.busy":"2023-10-27T08:27:40.202505Z","iopub.execute_input":"2023-10-27T08:27:40.203025Z","iopub.status.idle":"2023-10-27T08:27:40.213875Z","shell.execute_reply.started":"2023-10-27T08:27:40.202996Z","shell.execute_reply":"2023-10-27T08:27:40.212816Z"},"trusted":true},"execution_count":13,"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"7900"},"metadata":{}}]},{"cell_type":"code","source":"from datasets import Dataset, DatasetDict","metadata":{"execution":{"iopub.status.busy":"2023-10-27T08:27:40.215222Z","iopub.execute_input":"2023-10-27T08:27:40.215599Z","iopub.status.idle":"2023-10-27T08:27:40.220840Z","shell.execute_reply.started":"2023-10-27T08:27:40.215547Z","shell.execute_reply":"2023-10-27T08:27:40.219821Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"dataset_dict = DatasetDict({\n    \"train\": Dataset.from_dict({key: [item[key] for item in train_data] for key in train_data[0]}),\n    \"test\" : Dataset.from_dict({key: [item[key] for item in test_data] for key in test_data[0]})\n})","metadata":{"execution":{"iopub.status.busy":"2023-10-27T08:27:40.222247Z","iopub.execute_input":"2023-10-27T08:27:40.222670Z","iopub.status.idle":"2023-10-27T08:27:40.298890Z","shell.execute_reply.started":"2023-10-27T08:27:40.222632Z","shell.execute_reply":"2023-10-27T08:27:40.298097Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"dataset_dict[\"train\"][0:10]","metadata":{"execution":{"iopub.status.busy":"2023-10-27T08:27:40.299967Z","iopub.execute_input":"2023-10-27T08:27:40.300239Z","iopub.status.idle":"2023-10-27T08:27:40.308508Z","shell.execute_reply.started":"2023-10-27T08:27:40.300214Z","shell.execute_reply":"2023-10-27T08:27:40.307592Z"},"trusted":true},"execution_count":16,"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"{'label': [0, 0, 0, 0, 0, 1, 1, 0, 1, 0],\n 'sentence': ['What people are we talking about?',\n  'He did, by leveraging his endorsement for putting progressive policies into the Democratic party platform.',\n  \"I mean, i'd be more than happy to receive a check in the mail, if you're listening Hillary...\",\n  'The contradiction is real..',\n  'Meanwhile in Loompaland, Trump is winning and anyone that says otherwise is a shill.',\n  'The US is just an inherently more violent place, just look at our track record.',\n  'LIBRULS ARE WHY CONSERVATIVES KILL PEOPLE!',\n  'Those are rigged too, *duh*',\n  'They get abortions all the time.',\n  'That sounds like enough'],\n 'idx': [38146, 3353, 15392, 7492, 3202, 29470, 38016, 1149, 35816, 28515]}"},"metadata":{}}]},{"cell_type":"code","source":"from setfit import sample_dataset\n\ntrain_dataset = dataset_dict[\"train\"]\ntrain_dataset[0:10]","metadata":{"execution":{"iopub.status.busy":"2023-10-27T08:27:40.309806Z","iopub.execute_input":"2023-10-27T08:27:40.310421Z","iopub.status.idle":"2023-10-27T08:27:46.720635Z","shell.execute_reply.started":"2023-10-27T08:27:40.310368Z","shell.execute_reply":"2023-10-27T08:27:46.719724Z"},"trusted":true},"execution_count":17,"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"{'label': [0, 0, 0, 0, 0, 1, 1, 0, 1, 0],\n 'sentence': ['What people are we talking about?',\n  'He did, by leveraging his endorsement for putting progressive policies into the Democratic party platform.',\n  \"I mean, i'd be more than happy to receive a check in the mail, if you're listening Hillary...\",\n  'The contradiction is real..',\n  'Meanwhile in Loompaland, Trump is winning and anyone that says otherwise is a shill.',\n  'The US is just an inherently more violent place, just look at our track record.',\n  'LIBRULS ARE WHY CONSERVATIVES KILL PEOPLE!',\n  'Those are rigged too, *duh*',\n  'They get abortions all the time.',\n  'That sounds like enough'],\n 'idx': [38146, 3353, 15392, 7492, 3202, 29470, 38016, 1149, 35816, 28515]}"},"metadata":{}}]},{"cell_type":"code","source":"eval_dataset = dataset_dict[\"test\"]","metadata":{"execution":{"iopub.status.busy":"2023-10-27T08:27:46.721962Z","iopub.execute_input":"2023-10-27T08:27:46.722312Z","iopub.status.idle":"2023-10-27T08:27:46.727086Z","shell.execute_reply.started":"2023-10-27T08:27:46.722279Z","shell.execute_reply":"2023-10-27T08:27:46.726047Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"model_id = \"sentence-transformers/paraphrase-mpnet-base-v2\"","metadata":{"execution":{"iopub.status.busy":"2023-10-27T08:27:46.728638Z","iopub.execute_input":"2023-10-27T08:27:46.728975Z","iopub.status.idle":"2023-10-27T08:27:46.770748Z","shell.execute_reply.started":"2023-10-27T08:27:46.728939Z","shell.execute_reply":"2023-10-27T08:27:46.769520Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"from setfit import SetFitModel\n\nnum_classes = len(train_dataset.unique(\"label\"))\n# Assuming train_dataset is a list of dictionaries and 'label' is the key for the label\n# unique_labels = set(data['label'] for data in train_dataset)\n\n# # Calculate the number of unique classes\n# num_classes = len(unique_labels)\nmodel = SetFitModel.from_pretrained(model_id, use_differentiable_head=True, head_params={\"out_features\": num_classes})","metadata":{"execution":{"iopub.status.busy":"2023-10-27T08:27:46.772115Z","iopub.execute_input":"2023-10-27T08:27:46.772520Z","iopub.status.idle":"2023-10-27T08:27:57.177332Z","shell.execute_reply.started":"2023-10-27T08:27:46.772487Z","shell.execute_reply":"2023-10-27T08:27:57.176347Z"},"trusted":true},"execution_count":20,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading (…)lve/main/config.json:   0%|          | 0.00/594 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bf42459bba474067862b7d26e34bad50"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)f39ef/.gitattributes:   0%|          | 0.00/690 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"36ae1cf065014fd0ba997a873de6edce"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bb91b03aaa054055b17e7a0319416fa5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)0182ff39ef/README.md:   0%|          | 0.00/3.70k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d56b6005255f42fab2a18eb8e3d812de"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)82ff39ef/config.json:   0%|          | 0.00/594 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"27d4129d7e6f4da38a8a77f9787e68e2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)ce_transformers.json:   0%|          | 0.00/122 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"48cce61b4a974929afda2e7b3167ec45"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading pytorch_model.bin:   0%|          | 0.00/438M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"80123efdb3c0435f9828765ffb7c46c0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)nce_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"12f47fb5920f45169f7e0fd5978991a8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)cial_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"660502e53eaa4ecba44c6f2b2cc1557c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)f39ef/tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"79f96b0b4e204c49aabda19c21d5dc68"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)okenizer_config.json:   0%|          | 0.00/1.19k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f6102e3773a145cda65173661891e5ac"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)0182ff39ef/vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"312ac26c257040bd830a8a293ce0089b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)2ff39ef/modules.json:   0%|          | 0.00/229 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"abdda37c20db44bf88b892c60d0adad6"}},"metadata":{}},{"name":"stderr","text":"model_head.pkl not found on HuggingFace Hub, initialising classification head with random weights. You should TRAIN this model on a downstream task to use it for predictions and inference.\n","output_type":"stream"}]},{"cell_type":"code","source":"from sentence_transformers.losses import CosineSimilarityLoss\n\nfrom setfit import SetFitTrainer\n\ntrainer = SetFitTrainer(\n    model=model,\n    train_dataset=train_dataset,\n    eval_dataset=eval_dataset,\n    loss_class=CosineSimilarityLoss,\n    num_iterations=20,\n    column_mapping={\"sentence\": \"text\", \"label\": \"label\"},\n)","metadata":{"execution":{"iopub.status.busy":"2023-10-27T08:27:57.178711Z","iopub.execute_input":"2023-10-27T08:27:57.179004Z","iopub.status.idle":"2023-10-27T08:27:57.184520Z","shell.execute_reply.started":"2023-10-27T08:27:57.178978Z","shell.execute_reply":"2023-10-27T08:27:57.183422Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"trainer.freeze()\ntrainer.train(body_learning_rate=1e-5, num_epochs=1)","metadata":{"execution":{"iopub.status.busy":"2023-10-27T08:27:57.185630Z","iopub.execute_input":"2023-10-27T08:27:57.185907Z","iopub.status.idle":"2023-10-27T14:08:00.967783Z","shell.execute_reply.started":"2023-10-27T08:27:57.185882Z","shell.execute_reply":"2023-10-27T14:08:00.966994Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stderr","text":"Applying column mapping to training dataset\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Generating Training Pairs:   0%|          | 0/20 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0bbd23642df645bfabb112ac7c018cdd"}},"metadata":{}},{"name":"stderr","text":"***** Running training *****\n  Num examples = 1263840\n  Num epochs = 1\n  Total optimization steps = 78990\n  Total train batch size = 16\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"650d5dfa5d4049878d73a9ca632de254"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Iteration:   0%|          | 0/78990 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"58fb7f3d4b03447db551a9d94335f1ba"}},"metadata":{}}]},{"cell_type":"code","source":"trainer.unfreeze(keep_body_frozen=True)\ntrainer.train(learning_rate=1e-2, num_epochs=25)","metadata":{"execution":{"iopub.status.busy":"2023-10-27T14:12:41.518260Z","iopub.execute_input":"2023-10-27T14:12:41.518635Z","iopub.status.idle":"2023-10-27T17:46:23.711097Z","shell.execute_reply.started":"2023-10-27T14:12:41.518600Z","shell.execute_reply":"2023-10-27T17:46:23.709593Z"},"trusted":true},"execution_count":24,"outputs":[{"name":"stderr","text":"Applying column mapping to training dataset\nThe `max_length` is `None`. Using the maximum acceptable length according to the current model body: 512.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch:   0%|          | 0/25 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"39caa9ef7ca248abb44b8fa4ff77f417"}},"metadata":{}},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[24], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m trainer\u001b[38;5;241m.\u001b[39munfreeze(keep_body_frozen\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m----> 2\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1e-2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m25\u001b[39;49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/setfit/trainer.py:406\u001b[0m, in \u001b[0;36mSetFitTrainer.train\u001b[0;34m(self, num_epochs, batch_size, learning_rate, body_learning_rate, l2_weight, max_length, trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    395\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mmodel_body\u001b[38;5;241m.\u001b[39mfit(\n\u001b[1;32m    396\u001b[0m         train_objectives\u001b[38;5;241m=\u001b[39m[(train_dataloader, train_loss)],\n\u001b[1;32m    397\u001b[0m         epochs\u001b[38;5;241m=\u001b[39mnum_epochs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    401\u001b[0m         use_amp\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_amp,\n\u001b[1;32m    402\u001b[0m     )\n\u001b[1;32m    404\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mhas_differentiable_head \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_freeze:\n\u001b[1;32m    405\u001b[0m     \u001b[38;5;66;03m# Train the final classifier\u001b[39;00m\n\u001b[0;32m--> 406\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    407\u001b[0m \u001b[43m        \u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    408\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    409\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    410\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    411\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlearning_rate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    412\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody_learning_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody_learning_rate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    413\u001b[0m \u001b[43m        \u001b[49m\u001b[43ml2_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43ml2_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    414\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    415\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    416\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/setfit/modeling.py:307\u001b[0m, in \u001b[0;36mSetFitModel.fit\u001b[0;34m(self, x_train, y_train, num_epochs, batch_size, learning_rate, body_learning_rate, l2_weight, max_length, show_progress_bar)\u001b[0m\n\u001b[1;32m    304\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m    306\u001b[0m \u001b[38;5;66;03m# to model's device\u001b[39;00m\n\u001b[0;32m--> 307\u001b[0m features \u001b[38;5;241m=\u001b[39m {k: v\u001b[38;5;241m.\u001b[39mto(device) \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m features\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[1;32m    308\u001b[0m labels \u001b[38;5;241m=\u001b[39m labels\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m    310\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_body(features)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/setfit/modeling.py:307\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    304\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m    306\u001b[0m \u001b[38;5;66;03m# to model's device\u001b[39;00m\n\u001b[0;32m--> 307\u001b[0m features \u001b[38;5;241m=\u001b[39m {k: \u001b[43mv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m features\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[1;32m    308\u001b[0m labels \u001b[38;5;241m=\u001b[39m labels\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m    310\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_body(features)\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]},{"cell_type":"code","source":"trainer.evaluate()\n","metadata":{"execution":{"iopub.status.busy":"2023-10-27T17:46:24.103638Z","iopub.execute_input":"2023-10-27T17:46:24.103992Z","iopub.status.idle":"2023-10-27T17:46:36.138535Z","shell.execute_reply.started":"2023-10-27T17:46:24.103965Z","shell.execute_reply":"2023-10-27T17:46:36.137619Z"},"trusted":true},"execution_count":25,"outputs":[{"name":"stderr","text":"Applying column mapping to evaluation dataset\n***** Running evaluation *****\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/247 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7804e1c3bacf41538e231c29eff37e0f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/4.20k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5f29d83b366b49baa39bbedcc88d3f92"}},"metadata":{}},{"execution_count":25,"output_type":"execute_result","data":{"text/plain":"{'accuracy': 0.7889873417721519}"},"metadata":{}}]},{"cell_type":"code","source":"model._save_pretrained('save_directory')","metadata":{"execution":{"iopub.status.busy":"2023-10-27T17:47:09.815250Z","iopub.execute_input":"2023-10-27T17:47:09.815621Z","iopub.status.idle":"2023-10-27T17:47:10.488523Z","shell.execute_reply.started":"2023-10-27T17:47:09.815590Z","shell.execute_reply":"2023-10-27T17:47:10.487536Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}