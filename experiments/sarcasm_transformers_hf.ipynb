{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100",
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#pip install transformers"
      ],
      "metadata": {
        "id": "1N5FPAEgjyQv"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"Sarcasm classification using bidirectional encoder transformers\"\"\""
      ],
      "metadata": {
        "id": "0Uz1uCgzi8Wb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v9Dc8AvzfzdI",
        "outputId": "7afce353-e008-4453-cbcc-649d6f4f671e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive', force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "lpDpVF46f_bo"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Use StringIO to simulate a file object\n",
        "train_df = pd.read_csv('gdrive/My Drive/anlp_project/train-balanced-sarcasm.csv')"
      ],
      "metadata": {
        "id": "5xRVOT_EgCFq"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_df = pd.read_csv('gdrive/My Drive/anlp_project/test-balanced.csv')"
      ],
      "metadata": {
        "id": "S7348dZSCaDR"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df = train_df[train_df['subreddit']=='politics']"
      ],
      "metadata": {
        "id": "VLht-mPs6JMR"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df['full_comment'] = train_df['parent_comment'] + ' [SEP] ' + train_df['comment']"
      ],
      "metadata": {
        "id": "cYi-SXUv6WZn"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        },
        "id": "AhThuv9v6oi3",
        "outputId": "49fcf192-2447-4a57-fdc7-2f11723481e0"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    label                                            comment  \\\n",
              "0       0                                         NC and NH.   \n",
              "10      0  I think a significant amount would be against ...   \n",
              "17      0  because it's what really bothers him... and it...   \n",
              "22      0  Conservatism as an ideology is for sure a reac...   \n",
              "23      0  Maybe not control, but certainly that is evide...   \n",
              "\n",
              "                author subreddit  score  ups  downs     date  \\\n",
              "0            Trumpbart  politics      2   -1     -1  2016-10   \n",
              "10  ThisIsNotKimJongUn  politics     92   92      0  2016-09   \n",
              "17           kozmo1313  politics     15   -1     -1  2016-12   \n",
              "22     MayorMcCheese59  politics      1   -1     -1  2016-12   \n",
              "23             SunTzu-  politics      1   -1     -1  2016-10   \n",
              "\n",
              "            created_utc                                     parent_comment  \\\n",
              "0   2016-10-16 23:55:23  Yeah, I get that argument. At this point, I'd ...   \n",
              "10  2016-09-20 17:53:52  I bet if that money was poured into college de...   \n",
              "17  2016-12-26 20:10:45  He actually acts like a moody emo girl on twit...   \n",
              "22  2016-12-24 00:04:06  I still doubt that \"all conservatives stand fo...   \n",
              "23  2016-10-13 20:48:14  Today Russian media tweeted out that Wikileaks...   \n",
              "\n",
              "                                         full_comment  \n",
              "0   Yeah, I get that argument. At this point, I'd ...  \n",
              "10  I bet if that money was poured into college de...  \n",
              "17  He actually acts like a moody emo girl on twit...  \n",
              "22  I still doubt that \"all conservatives stand fo...  \n",
              "23  Today Russian media tweeted out that Wikileaks...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9856dcb9-9f86-40da-b272-99b6afa88fde\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>comment</th>\n",
              "      <th>author</th>\n",
              "      <th>subreddit</th>\n",
              "      <th>score</th>\n",
              "      <th>ups</th>\n",
              "      <th>downs</th>\n",
              "      <th>date</th>\n",
              "      <th>created_utc</th>\n",
              "      <th>parent_comment</th>\n",
              "      <th>full_comment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>NC and NH.</td>\n",
              "      <td>Trumpbart</td>\n",
              "      <td>politics</td>\n",
              "      <td>2</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>2016-10</td>\n",
              "      <td>2016-10-16 23:55:23</td>\n",
              "      <td>Yeah, I get that argument. At this point, I'd ...</td>\n",
              "      <td>Yeah, I get that argument. At this point, I'd ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>0</td>\n",
              "      <td>I think a significant amount would be against ...</td>\n",
              "      <td>ThisIsNotKimJongUn</td>\n",
              "      <td>politics</td>\n",
              "      <td>92</td>\n",
              "      <td>92</td>\n",
              "      <td>0</td>\n",
              "      <td>2016-09</td>\n",
              "      <td>2016-09-20 17:53:52</td>\n",
              "      <td>I bet if that money was poured into college de...</td>\n",
              "      <td>I bet if that money was poured into college de...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>0</td>\n",
              "      <td>because it's what really bothers him... and it...</td>\n",
              "      <td>kozmo1313</td>\n",
              "      <td>politics</td>\n",
              "      <td>15</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>2016-12</td>\n",
              "      <td>2016-12-26 20:10:45</td>\n",
              "      <td>He actually acts like a moody emo girl on twit...</td>\n",
              "      <td>He actually acts like a moody emo girl on twit...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>0</td>\n",
              "      <td>Conservatism as an ideology is for sure a reac...</td>\n",
              "      <td>MayorMcCheese59</td>\n",
              "      <td>politics</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>2016-12</td>\n",
              "      <td>2016-12-24 00:04:06</td>\n",
              "      <td>I still doubt that \"all conservatives stand fo...</td>\n",
              "      <td>I still doubt that \"all conservatives stand fo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>0</td>\n",
              "      <td>Maybe not control, but certainly that is evide...</td>\n",
              "      <td>SunTzu-</td>\n",
              "      <td>politics</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>2016-10</td>\n",
              "      <td>2016-10-13 20:48:14</td>\n",
              "      <td>Today Russian media tweeted out that Wikileaks...</td>\n",
              "      <td>Today Russian media tweeted out that Wikileaks...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9856dcb9-9f86-40da-b272-99b6afa88fde')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-9856dcb9-9f86-40da-b272-99b6afa88fde button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-9856dcb9-9f86-40da-b272-99b6afa88fde');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-2ee4c696-1fd0-4ca8-921f-a24265f0c9d7\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-2ee4c696-1fd0-4ca8-921f-a24265f0c9d7')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-2ee4c696-1fd0-4ca8-921f-a24265f0c9d7 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#test_df = pd.read_csv('gdrive/My Drive/anlp_project/SemEval2018-T3_gold_test_taskA_emoji.txt', sep='\\t')"
      ],
      "metadata": {
        "id": "lLQt1L2jgGCA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "#very basic preprocessing\n",
        "\n",
        "def preprocess_tweet(tweet):\n",
        "\n",
        "\n",
        "    # replace possible sarcasm expressions with possiblity\n",
        "    re.sub(r'\\. \\.\\.', ' possibility ', tweet)\n",
        "    re.sub(r'\\. \\.\\.\\.', ' possibility ', tweet)\n",
        "    #re.sub(r'\\.\\.\\.\\.', ' continuity ', tweet)\n",
        "\n",
        "     # Replace patterns like \"250,000\", \"3,600\" with \"NUM\"\n",
        "    #text = re.sub(r'\\b\\d{1,3}(?:,\\d{3})*(?!\\d)', 'num', tweet)\n",
        "\n",
        "    # Replace urls\n",
        "    tweet = re.sub(r\"http\\S+|www\\S+|https\\S+\", 'URL', tweet)\n",
        "\n",
        "    #replace numbers\n",
        "    #tweet = re.sub(r'^\\d+$', 'num', tweet)\n",
        "    tweet = re.sub(r'\\b\\d+\\b', 'num', tweet)\n",
        "\n",
        "\n",
        "    return tweet\n"
      ],
      "metadata": {
        "id": "2l6EryRggLD9"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df['full_comment'] = train_df['full_comment'].astype(str)"
      ],
      "metadata": {
        "id": "dh1CnS7a71TZ"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df['text_prep'] = train_df['full_comment'].apply(lambda x: preprocess_tweet(x))"
      ],
      "metadata": {
        "id": "hWYnsI1Ig5KF"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "train_df, test_df = train_test_split(train_df, test_size=0.2, stratify=train_df['label'], random_state=42)"
      ],
      "metadata": {
        "id": "J3sS2Y6wGMgz"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_df), len(test_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o1u3Z28IGu0k",
        "outputId": "7427ba3c-b2c7-45c6-8f5c-d20647c62c2b"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(31596, 7900)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_tweets = train_df['text_prep'].tolist()"
      ],
      "metadata": {
        "id": "7fWKvTb2hyyE"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tokenizers import Tokenizer, models, trainers, pre_tokenizers, decoders, processors\n",
        "\n",
        "# Initialize a tokenizer\n",
        "tokenizer = Tokenizer(models.BPE())\n",
        "\n",
        "# Use the pre-tokenizer responsible for splitting the input into words\n",
        "tokenizer.pre_tokenizer = pre_tokenizers.Whitespace()\n",
        "\n",
        "# Train the tokenizer\n",
        "trainer = trainers.BpeTrainer(vocab_size=50000, show_progress=True)\n",
        "tokenizer.train_from_iterator(train_tweets, trainer=trainer)  # train from iterator\n",
        "\n",
        "# Once it's trained, save it\n",
        "tokenizer.save('trained_tokenizer.json')\n"
      ],
      "metadata": {
        "id": "31lGSsNjhF4L"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_len = int(train_df['text_prep'].apply(len).quantile(0.95))\n",
        "max_len"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0OWI1pBG88vZ",
        "outputId": "ff51846a-d90a-4b72-df78-699710b5fab2"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "504"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "class TweetDataset(Dataset):\n",
        "    def __init__(self, tweets, labels, tokenizer, max_len):\n",
        "        self.tweets = tweets\n",
        "        self.labels = labels\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.tweets)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        tweet = self.tweets[idx]\n",
        "        label = self.labels[idx]\n",
        "        encoding = self.tokenizer.encode(tweet)\n",
        "        tokens = encoding.ids\n",
        "\n",
        "        # Truncate or pad the tokens\n",
        "        if len(tokens) > self.max_len:\n",
        "            tokens = tokens[:self.max_len]\n",
        "        else:\n",
        "            tokens += [0] * (self.max_len - len(tokens))\n",
        "\n",
        "        # The attention mask should have 1 for real tokens and 0 for padding\n",
        "        attention_mask = [1 if token_id > 0 else 0 for token_id in tokens]\n",
        "\n",
        "        return {\n",
        "            'input_ids': torch.tensor(tokens),\n",
        "            'attention_mask': torch.tensor(attention_mask),\n",
        "            'label': torch.tensor(label, dtype=torch.long)\n",
        "        }\n",
        "\n",
        "# Example\n",
        "tweets = train_tweets\n",
        "labels = train_df['label'].tolist()  # 0 for non-ironic and 1 for ironic\n",
        "dataset = TweetDataset(tweets, labels, tokenizer, max_len=500)\n",
        "loader = DataLoader(dataset, batch_size=32, shuffle=True)\n"
      ],
      "metadata": {
        "id": "dY-JRY9BiLMY"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_tweets = test_df['text_prep'].tolist()\n",
        "test_labels = test_df['label'].tolist()\n",
        "test_dataset = TweetDataset(test_tweets, test_labels, tokenizer, max_len=500)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=True)"
      ],
      "metadata": {
        "id": "E2GlJdB5qcan"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import BertModel\n",
        "from transformers.modeling_outputs import BaseModelOutputWithPoolingAndCrossAttentions\n",
        "from torch.nn import Linear\n",
        "\n",
        "class TweetClassifier(torch.nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super(TweetClassifier, self).__init__()\n",
        "\n",
        "        # Transformer encoder\n",
        "        self.encoder = BertModel(config)\n",
        "\n",
        "        # Positional embeddings (they are by default included in the TransformerModel in Hugging Face)\n",
        "\n",
        "        # Classification head\n",
        "        self.classifier = Linear(config.hidden_size, 2)  # Binary classification\n",
        "\n",
        "    def forward(self, input_ids, attention_mask=None):\n",
        "        # Pass through transformer\n",
        "        outputs: BaseModelOutputWithPoolingAndCrossAttentions = self.encoder(\n",
        "            input_ids, attention_mask=attention_mask\n",
        "        )\n",
        "\n",
        "        # Use CLS token for classification task\n",
        "        cls_output = outputs.last_hidden_state[:, 0]\n",
        "\n",
        "        # Pass through classification head\n",
        "        logits = self.classifier(cls_output)\n",
        "\n",
        "        return logits\n",
        "\n",
        "\n",
        "from transformers import BertConfig, BertModel\n",
        "\n",
        "# Configuration for the transformer\n",
        "config = BertConfig(\n",
        "    vocab_size=tokenizer.get_vocab_size(),\n",
        "    hidden_size=512,\n",
        "    num_attention_heads=4,\n",
        "    num_hidden_layers=3,\n",
        "    intermediate_size=2048,\n",
        "    hidden_dropout_prob=0.1,\n",
        "    attention_probs_dropout_prob=0.1\n",
        ")\n",
        "\n",
        "model = TweetClassifier(config)\n"
      ],
      "metadata": {
        "id": "djERppbNikW4"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ZbCK6wzjhBJ",
        "outputId": "042f932f-354b-40a3-f5c1-c279671afc3c"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TweetClassifier(\n",
              "  (encoder): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(50000, 512, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 512)\n",
              "      (token_type_embeddings): Embedding(2, 512)\n",
              "      (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0-2): 3 x BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=512, out_features=512, bias=True)\n",
              "              (key): Linear(in_features=512, out_features=512, bias=True)\n",
              "              (value): Linear(in_features=512, out_features=512, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=512, out_features=512, bias=True)\n",
              "              (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=512, out_features=2048, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=2048, out_features=512, bias=True)\n",
              "            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=512, out_features=512, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (classifier): Linear(in_features=512, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score\n",
        "\n",
        "# Assuming you have set up your model, optimizer, and loss criterion\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=0.0001)\n",
        "criterion = torch.nn.BCEWithLogitsLoss()\n",
        "\n",
        "epochs = 3\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    all_predictions = []\n",
        "    all_labels = []\n",
        "    train_probabilities = []\n",
        "    total_loss = 0.0\n",
        "\n",
        "    for batch in loader:\n",
        "        input_ids = batch['input_ids'].to(device)\n",
        "        attention_mask = batch['attention_mask'].to(device)\n",
        "\n",
        "        # One-hot encode labels before sending them to the model and loss function\n",
        "        labels_one_hot = torch.nn.functional.one_hot(batch['label']).to(torch.float32).to(device)\n",
        "\n",
        "        outputs = model(input_ids, attention_mask=attention_mask)\n",
        "        loss = criterion(outputs, labels_one_hot)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Get the predictions\n",
        "        predictions = torch.argmax(outputs, dim=1)\n",
        "        all_predictions.extend(predictions.cpu().numpy())\n",
        "\n",
        "        # Extract binary format from one-hot encoded labels for evaluation\n",
        "        labels_binary = [label[1] for label in labels_one_hot.cpu().numpy()]\n",
        "        all_labels.extend(labels_binary)\n",
        "\n",
        "        total_loss += loss.item()\n",
        "        probs = torch.nn.functional.softmax(outputs.detach(), dim=1)[:, 1].cpu().numpy()\n",
        "        train_probabilities.extend(probs)\n",
        "\n",
        "    avg_loss = total_loss / len(loader)\n",
        "    accuracy = accuracy_score(all_labels, all_predictions)\n",
        "    f1 = f1_score(all_labels, all_predictions)\n",
        "    # Compute ROC AUC score for the positive class\n",
        "    train_auc = roc_auc_score(all_labels, train_probabilities)\n",
        "\n",
        "    print(f\"Epoch {epoch + 1}/{epochs} Loss: {avg_loss:.4f} Accuracy: {accuracy:.4f} F1: {f1:.4f}, AUC: {train_auc:.4f}\")\n",
        "\n",
        "    # Evaluation\n",
        "    model.eval()\n",
        "    test_predictions = []\n",
        "    test_labels = []\n",
        "    test_probabilities = []\n",
        "    with torch.no_grad():\n",
        "      for batch in test_loader:\n",
        "        input_ids = batch['input_ids'].to(device)\n",
        "        attention_mask = batch['attention_mask'].to(device)\n",
        "        labels = batch['label'].to(device)\n",
        "        labels_one_hot = torch.nn.functional.one_hot(batch['label']).to(torch.float32).to(device)\n",
        "\n",
        "        outputs = model(input_ids, attention_mask=attention_mask)\n",
        "        predictions = torch.argmax(outputs, dim=1)\n",
        "        test_predictions.extend(predictions.cpu().numpy())\n",
        "\n",
        "        labels_binary = [label[1] for label in labels_one_hot.cpu().numpy()]\n",
        "        test_labels.extend(labels_binary)\n",
        "        probs = torch.nn.functional.softmax(outputs, dim=1)[:, 1].cpu().numpy()\n",
        "        test_probabilities.extend(probs)\n",
        "\n",
        "      test_accuracy = accuracy_score(test_labels, test_predictions)\n",
        "      test_f1 = f1_score(test_labels, test_predictions)\n",
        "      # Compute ROC AUC score for the positive class for the test set\n",
        "      test_auc = roc_auc_score(test_labels, test_probabilities)\n",
        "      print(f\"Test Accuracy: {test_accuracy:.4f} Test F1: {test_f1:.4f} Test AUC: {test_auc:.4f}\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l_e9lDLYjcTl",
        "outputId": "2b5c4ea3-fddf-45c9-e986-a207126843ef"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3 Loss: 0.6289 Accuracy: 0.6350 F1: 0.7282, AUC: 0.6675\n",
            "Test Accuracy: 0.6849 Test F1: 0.7428 Test AUC: 0.7433\n",
            "Epoch 2/3 Loss: 0.5220 Accuracy: 0.7418 F1: 0.7925, AUC: 0.8063\n",
            "Test Accuracy: 0.6880 Test F1: 0.7237 Test AUC: 0.7624\n",
            "Epoch 3/3 Loss: 0.3848 Accuracy: 0.8321 F1: 0.8629, AUC: 0.9027\n",
            "Test Accuracy: 0.6866 Test F1: 0.7644 Test AUC: 0.7277\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluation\n",
        "model.eval()\n",
        "test_predictions = []\n",
        "test_labels = []\n",
        "test_probabilities = []\n",
        "with torch.no_grad():\n",
        "  for batch in test_loader:\n",
        "    input_ids = batch['input_ids'].to(device)\n",
        "    attention_mask = batch['attention_mask'].to(device)\n",
        "    labels = batch['label'].to(device)\n",
        "    labels_one_hot = torch.nn.functional.one_hot(batch['label']).to(torch.float32).to(device)\n",
        "\n",
        "    outputs = model(input_ids, attention_mask=attention_mask)\n",
        "    predictions = torch.argmax(outputs, dim=1)\n",
        "    test_predictions.extend(predictions.cpu().numpy())\n",
        "\n",
        "    labels_binary = [label[1] for label in labels_one_hot.cpu().numpy()]\n",
        "    test_labels.extend(labels_binary)\n",
        "    probs = torch.nn.functional.softmax(outputs, dim=1)[:, 1].cpu().numpy()\n",
        "    test_probabilities.extend(probs)\n",
        "\n",
        "  test_accuracy = accuracy_score(test_labels, test_predictions)\n",
        "  test_f1 = f1_score(test_labels, test_predictions)\n",
        "  # Compute ROC AUC score for the positive class for the test set\n",
        "  test_auc = roc_auc_score(test_labels, test_probabilities)\n",
        "  print(f\"Test Accuracy: {test_accuracy:.4f} Test F1: {test_f1:.4f} Test AUC: {test_auc:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3N7K6VNBmEQV",
        "outputId": "b23b9a40-31db-4c43-cf68-e8ebcb15bf3b"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 0.6866 Test F1: 0.7644 Test AUC: 0.7277\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_save_path = 'gdrive/My Drive/anlp_project/transformers/sarcasm_nonbert_model_weights.pth'\n",
        "tokenizer_save_path = 'gdrive/My Drive/anlp_project/transformers/sarcasm_tokenizer.json'\n",
        "\n",
        "# Save model weights\n",
        "torch.save(model.state_dict(), model_save_path)\n",
        "# Save tokenizer\n",
        "tokenizer.save(tokenizer_save_path)\n"
      ],
      "metadata": {
        "id": "yND1JeJTroT0"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Loading code\n",
        "from tokenizers import Tokenizer\n",
        "\n",
        "# Load model\n",
        "model = TweetClassifier(config)\n",
        "model.load_state_dict(torch.load(model_save_path))\n",
        "model.eval()\n",
        "\n",
        "# Load tokenizer\n",
        "tokenizer = Tokenizer.from_file(tokenizer_save_path)"
      ],
      "metadata": {
        "id": "WbKIiZBAuYU3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}