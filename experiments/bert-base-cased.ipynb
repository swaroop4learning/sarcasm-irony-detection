{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-11-02T13:00:28.407331Z","iopub.execute_input":"2023-11-02T13:00:28.407724Z","iopub.status.idle":"2023-11-02T13:00:28.783697Z","shell.execute_reply.started":"2023-11-02T13:00:28.407689Z","shell.execute_reply":"2023-11-02T13:00:28.782831Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/input/isemeval-dataset/iSarcasmEval-main/LICENSE\n/kaggle/input/isemeval-dataset/iSarcasmEval-main/README.md\n/kaggle/input/isemeval-dataset/iSarcasmEval-main/third-party annotations/README.md\n/kaggle/input/isemeval-dataset/iSarcasmEval-main/third-party annotations/arabic_task_a.csv\n/kaggle/input/isemeval-dataset/iSarcasmEval-main/third-party annotations/english_task_a.csv\n/kaggle/input/isemeval-dataset/iSarcasmEval-main/third-party annotations/arabic_task_c.csv\n/kaggle/input/isemeval-dataset/iSarcasmEval-main/third-party annotations/english_task_c.csv\n/kaggle/input/isemeval-dataset/iSarcasmEval-main/test/task_B_En_test.csv\n/kaggle/input/isemeval-dataset/iSarcasmEval-main/test/task_A_Ar_test.csv\n/kaggle/input/isemeval-dataset/iSarcasmEval-main/test/task_C_Ar_test.csv\n/kaggle/input/isemeval-dataset/iSarcasmEval-main/test/task_C_En_test.csv\n/kaggle/input/isemeval-dataset/iSarcasmEval-main/test/task_A_En_test.csv\n/kaggle/input/isemeval-dataset/iSarcasmEval-main/train/train.En.csv\n/kaggle/input/isemeval-dataset/iSarcasmEval-main/train/train.Ar.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"# Install libraries\n!pip install transformers datasets evaluate","metadata":{"execution":{"iopub.status.busy":"2023-11-02T13:00:28.785482Z","iopub.execute_input":"2023-11-02T13:00:28.785925Z","iopub.status.idle":"2023-11-02T13:00:42.748740Z","shell.execute_reply.started":"2023-11-02T13:00:28.785896Z","shell.execute_reply":"2023-11-02T13:00:42.747499Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.33.0)\nRequirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (2.1.0)\nCollecting evaluate\n  Downloading evaluate-0.4.1-py3-none-any.whl (84 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.12.2)\nRequirement already satisfied: huggingface-hub<1.0,>=0.15.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.16.4)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.23.5)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2023.6.3)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.31.0)\nRequirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.13.3)\nRequirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.3.3)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.66.1)\nRequirement already satisfied: pyarrow>=5.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (11.0.0)\nRequirement already satisfied: dill in /opt/conda/lib/python3.10/site-packages (from datasets) (0.3.7)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets) (2.0.2)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets) (3.3.0)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets) (0.70.15)\nRequirement already satisfied: fsspec[http]>=2021.05.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (2023.9.0)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets) (3.8.4)\nRequirement already satisfied: responses<0.19 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.18.0)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (23.1.0)\nRequirement already satisfied: charset-normalizer<4.0,>=2.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (3.1.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.4)\nRequirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.2)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.9.2)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.3)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (4.6.3)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.0.9)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2023.7.22)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2.8.2)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2023.3)\nRequirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2023.3)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\nInstalling collected packages: evaluate\nSuccessfully installed evaluate-0.4.1\n","output_type":"stream"}]},{"cell_type":"code","source":"# Data processing\nimport pandas as pd\nimport numpy as np\n\n# Modeling\nimport tensorflow as tf\nfrom transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer, EarlyStoppingCallback, TextClassificationPipeline\n\n# Hugging Face Dataset\nfrom datasets import Dataset\n\n# Model performance evaluation\nimport evaluate","metadata":{"execution":{"iopub.status.busy":"2023-11-02T13:00:42.750762Z","iopub.execute_input":"2023-11-02T13:00:42.751697Z","iopub.status.idle":"2023-11-02T13:00:59.123969Z","shell.execute_reply.started":"2023-11-02T13:00:42.751656Z","shell.execute_reply":"2023-11-02T13:00:59.123182Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"}]},{"cell_type":"code","source":"import csv\n\n# Define the CSV file path\ncsv_file = '/kaggle/input/isemeval-dataset/iSarcasmEval-main/test/task_A_En_test.csv'\n\n# Initialize an empty list to store the data\ndata_test = []\n\n# Open the CSV file\nwith open(csv_file, mode='r', newline='') as file:\n    # Create a CSV reader\n    reader = csv.reader(file)\n\n    # Skip the header row if it exists (optional)\n    header = next(reader)\n\n    # Iterate over the rows in the CSV file\n    for row in reader:\n        data_test.append(row)\n","metadata":{"execution":{"iopub.status.busy":"2023-11-02T13:00:59.126872Z","iopub.execute_input":"2023-11-02T13:00:59.128014Z","iopub.status.idle":"2023-11-02T13:00:59.143547Z","shell.execute_reply.started":"2023-11-02T13:00:59.127983Z","shell.execute_reply":"2023-11-02T13:00:59.142721Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"data_test[0:2]","metadata":{"execution":{"iopub.status.busy":"2023-11-02T13:00:59.144655Z","iopub.execute_input":"2023-11-02T13:00:59.144962Z","iopub.status.idle":"2023-11-02T13:00:59.152546Z","shell.execute_reply.started":"2023-11-02T13:00:59.144937Z","shell.execute_reply":"2023-11-02T13:00:59.151483Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"[[\"Size on the the Toulouse team, That pack is monstrous. \\n\\nI can't see a Welsh region ever winning this, Money talks as they say .\",\n  '0'],\n ['Pinball!', '0']]"},"metadata":{}}]},{"cell_type":"code","source":"data_test = pd.DataFrame(data_test)\n# Assuming 'data_test' is your DataFrame\ndata_test = data_test.rename(columns={0: 'headline', 1: 'label'})\n\n# Now, your DataFrame columns are renamed\n","metadata":{"execution":{"iopub.status.busy":"2023-11-02T13:00:59.153957Z","iopub.execute_input":"2023-11-02T13:00:59.154601Z","iopub.status.idle":"2023-11-02T13:00:59.167061Z","shell.execute_reply.started":"2023-11-02T13:00:59.154566Z","shell.execute_reply":"2023-11-02T13:00:59.166225Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"data_test.head()","metadata":{"execution":{"iopub.status.busy":"2023-11-02T13:00:59.168092Z","iopub.execute_input":"2023-11-02T13:00:59.168349Z","iopub.status.idle":"2023-11-02T13:00:59.193608Z","shell.execute_reply.started":"2023-11-02T13:00:59.168328Z","shell.execute_reply":"2023-11-02T13:00:59.192608Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"                                            headline label\n0  Size on the the Toulouse team, That pack is mo...     0\n1                                           Pinball!     0\n2  So the Scottish Government want people to get ...     1\n3  villainous pro tip : change the device name on...     0\n4                    I would date any of these men 🥺     0","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>headline</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Size on the the Toulouse team, That pack is mo...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Pinball!</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>So the Scottish Government want people to get ...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>villainous pro tip : change the device name on...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>I would date any of these men 🥺</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"import csv\n\n# Define the CSV file path\ncsv_file = '/kaggle/input/isemeval-dataset/iSarcasmEval-main/train/train.En.csv'\n\n# Initialize an empty list to store the data\ndata_train = []\n\n# Open the CSV file\nwith open(csv_file, mode='r', newline='') as file:\n    # Create a CSV reader\n    reader = csv.reader(file)\n\n    # Skip the header row if it exists (optional)\n    header = next(reader)\n\n    # Iterate over the rows in the CSV file\n    for row in reader:\n        # Append only the first two values (columns) from each row\n        data_train.append(row[1:3])\n\n# Now, 'data_test' contains the first two columns of the CSV data\n","metadata":{"execution":{"iopub.status.busy":"2023-11-02T13:00:59.194736Z","iopub.execute_input":"2023-11-02T13:00:59.195011Z","iopub.status.idle":"2023-11-02T13:00:59.222806Z","shell.execute_reply.started":"2023-11-02T13:00:59.194989Z","shell.execute_reply":"2023-11-02T13:00:59.222118Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"data_train = pd.DataFrame(data_train)\n# Assuming 'data_test' is your DataFrame\ndata_train = data_train.rename(columns={0: 'headline', 1: 'label'})","metadata":{"execution":{"iopub.status.busy":"2023-11-02T13:00:59.223760Z","iopub.execute_input":"2023-11-02T13:00:59.224053Z","iopub.status.idle":"2023-11-02T13:00:59.230250Z","shell.execute_reply.started":"2023-11-02T13:00:59.224030Z","shell.execute_reply":"2023-11-02T13:00:59.229344Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"# Assuming you've already loaded your CSV data into a DataFrame 'data_test'\n\n# Convert the 'label' column to integers\ndata_test['label'] = data_test['label'].astype(int)\ndata_train['label'] = data_train['label'].astype(int)\n","metadata":{"execution":{"iopub.status.busy":"2023-11-02T13:00:59.233723Z","iopub.execute_input":"2023-11-02T13:00:59.234080Z","iopub.status.idle":"2023-11-02T13:00:59.245310Z","shell.execute_reply.started":"2023-11-02T13:00:59.234037Z","shell.execute_reply":"2023-11-02T13:00:59.244421Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"data_train.head()","metadata":{"execution":{"iopub.status.busy":"2023-11-02T13:00:59.246499Z","iopub.execute_input":"2023-11-02T13:00:59.246760Z","iopub.status.idle":"2023-11-02T13:00:59.260057Z","shell.execute_reply.started":"2023-11-02T13:00:59.246738Z","shell.execute_reply":"2023-11-02T13:00:59.259154Z"},"trusted":true},"execution_count":11,"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"                                            headline  label\n0  The only thing I got from college is a caffein...      1\n1  I love it when professors draw a big question ...      1\n2  Remember the hundred emails from companies whe...      1\n3  Today my pop-pop told me I was not “forced” to...      1\n4  @VolphanCarol @littlewhitty @mysticalmanatee I...      1","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>headline</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>The only thing I got from college is a caffein...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>I love it when professors draw a big question ...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Remember the hundred emails from companies whe...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Today my pop-pop told me I was not “forced” to...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>@VolphanCarol @littlewhitty @mysticalmanatee I...</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"data_train['label'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2023-11-02T13:00:59.261238Z","iopub.execute_input":"2023-11-02T13:00:59.261510Z","iopub.status.idle":"2023-11-02T13:00:59.278548Z","shell.execute_reply.started":"2023-11-02T13:00:59.261486Z","shell.execute_reply":"2023-11-02T13:00:59.277643Z"},"trusted":true},"execution_count":12,"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"label\n0    2601\n1     867\nName: count, dtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"data_test['label'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2023-11-02T13:00:59.279577Z","iopub.execute_input":"2023-11-02T13:00:59.279853Z","iopub.status.idle":"2023-11-02T13:00:59.287884Z","shell.execute_reply.started":"2023-11-02T13:00:59.279824Z","shell.execute_reply":"2023-11-02T13:00:59.287064Z"},"trusted":true},"execution_count":13,"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"label\n0    1200\n1     200\nName: count, dtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"# Install libraries\n# !pip install transformers datasets evaluate","metadata":{"execution":{"iopub.status.busy":"2023-11-02T13:00:59.288902Z","iopub.execute_input":"2023-11-02T13:00:59.289201Z","iopub.status.idle":"2023-11-02T13:00:59.298447Z","shell.execute_reply.started":"2023-11-02T13:00:59.289162Z","shell.execute_reply":"2023-11-02T13:00:59.297543Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"# Convert pyhton dataframe to Hugging Face arrow dataset\nhg_train_data = Dataset.from_pandas(data_train)\nhg_test_data = Dataset.from_pandas(data_test)","metadata":{"execution":{"iopub.status.busy":"2023-11-02T13:00:59.299560Z","iopub.execute_input":"2023-11-02T13:00:59.299973Z","iopub.status.idle":"2023-11-02T13:00:59.329542Z","shell.execute_reply.started":"2023-11-02T13:00:59.299942Z","shell.execute_reply":"2023-11-02T13:00:59.328547Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"# Length of the Dataset\nprint(f'The length of hg_train_data is {len(hg_train_data)}.\\n')\n\n# Check one review\nhg_train_data[0]","metadata":{"execution":{"iopub.status.busy":"2023-11-02T13:00:59.331499Z","iopub.execute_input":"2023-11-02T13:00:59.332152Z","iopub.status.idle":"2023-11-02T13:00:59.340979Z","shell.execute_reply.started":"2023-11-02T13:00:59.332118Z","shell.execute_reply":"2023-11-02T13:00:59.340000Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"The length of hg_train_data is 3468.\n\n","output_type":"stream"},{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"{'headline': 'The only thing I got from college is a caffeine addiction',\n 'label': 1}"},"metadata":{}}]},{"cell_type":"code","source":"# Tokenizer from a pretrained model\ntokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")\n\n# Take a look at the tokenizer\ntokenizer","metadata":{"execution":{"iopub.status.busy":"2023-11-02T13:00:59.342378Z","iopub.execute_input":"2023-11-02T13:00:59.342657Z","iopub.status.idle":"2023-11-02T13:01:00.099033Z","shell.execute_reply.started":"2023-11-02T13:00:59.342633Z","shell.execute_reply":"2023-11-02T13:01:00.098143Z"},"trusted":true},"execution_count":17,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading (…)okenizer_config.json:   0%|          | 0.00/29.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d53a914913e142b89c44befcc6475b2d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)lve/main/config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f9283d05ec2b47c6848dc5b98f00fa6d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/213k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dc63348f83314d598528478cde57185e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)/main/tokenizer.json:   0%|          | 0.00/436k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"da682fa380124f6ba460cefb2a444d67"}},"metadata":{}},{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"BertTokenizerFast(name_or_path='bert-base-cased', vocab_size=28996, model_max_length=512, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'}, clean_up_tokenization_spaces=True)"},"metadata":{}}]},{"cell_type":"code","source":"# Mapping between special tokens and their IDs.\nprint(f'The unknown token is {tokenizer.unk_token} and the ID for the unkown token is {tokenizer.unk_token_id}.')\nprint(f'The seperator token is {tokenizer.sep_token} and the ID for the seperator token is {tokenizer.sep_token_id}.')\nprint(f'The pad token is {tokenizer.pad_token} and the ID for the pad token is {tokenizer.pad_token_id}.')\nprint(f'The sentence level classification token is {tokenizer.cls_token} and the ID for the classification token is {tokenizer.cls_token_id}.')\nprint(f'The mask token is {tokenizer.mask_token} and the ID for the mask token is {tokenizer.mask_token_id}.')","metadata":{"execution":{"iopub.status.busy":"2023-11-02T13:01:00.100359Z","iopub.execute_input":"2023-11-02T13:01:00.100709Z","iopub.status.idle":"2023-11-02T13:01:00.107107Z","shell.execute_reply.started":"2023-11-02T13:01:00.100678Z","shell.execute_reply":"2023-11-02T13:01:00.106180Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"The unknown token is [UNK] and the ID for the unkown token is 100.\nThe seperator token is [SEP] and the ID for the seperator token is 102.\nThe pad token is [PAD] and the ID for the pad token is 0.\nThe sentence level classification token is [CLS] and the ID for the classification token is 101.\nThe mask token is [MASK] and the ID for the mask token is 103.\n","output_type":"stream"}]},{"cell_type":"code","source":"# Funtion to tokenize data\ndef tokenize_dataset(data):\n    return tokenizer(data[\"headline\"], \n                     max_length=32, \n                     truncation=True, \n                     padding=\"max_length\")\n\n# Tokenize the dataset\ndataset_train = hg_train_data.map(tokenize_dataset)\ndataset_test = hg_test_data.map(tokenize_dataset)","metadata":{"execution":{"iopub.status.busy":"2023-11-02T13:01:00.108889Z","iopub.execute_input":"2023-11-02T13:01:00.109196Z","iopub.status.idle":"2023-11-02T13:01:01.646369Z","shell.execute_reply.started":"2023-11-02T13:01:00.109172Z","shell.execute_reply":"2023-11-02T13:01:01.645343Z"},"trusted":true},"execution_count":19,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/3468 [00:00<?, ?ex/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0f91ec267897462f951d6acce5bf72cb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1400 [00:00<?, ?ex/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"269d768b01734b9c8a7761edddf6939d"}},"metadata":{}}]},{"cell_type":"code","source":"# Take a look at the data\nprint(dataset_train)\nprint(dataset_test)","metadata":{"execution":{"iopub.status.busy":"2023-11-02T13:01:01.647964Z","iopub.execute_input":"2023-11-02T13:01:01.648824Z","iopub.status.idle":"2023-11-02T13:01:01.654023Z","shell.execute_reply.started":"2023-11-02T13:01:01.648763Z","shell.execute_reply":"2023-11-02T13:01:01.652869Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stdout","text":"Dataset({\n    features: ['headline', 'label', 'input_ids', 'token_type_ids', 'attention_mask'],\n    num_rows: 3468\n})\nDataset({\n    features: ['headline', 'label', 'input_ids', 'token_type_ids', 'attention_mask'],\n    num_rows: 1400\n})\n","output_type":"stream"}]},{"cell_type":"code","source":"dataset_train[0]","metadata":{"execution":{"iopub.status.busy":"2023-11-02T13:01:01.655377Z","iopub.execute_input":"2023-11-02T13:01:01.655732Z","iopub.status.idle":"2023-11-02T13:01:01.671082Z","shell.execute_reply.started":"2023-11-02T13:01:01.655702Z","shell.execute_reply":"2023-11-02T13:01:01.670051Z"},"trusted":true},"execution_count":21,"outputs":[{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"{'headline': 'The only thing I got from college is a caffeine addiction',\n 'label': 1,\n 'input_ids': [101,\n  1109,\n  1178,\n  1645,\n  146,\n  1400,\n  1121,\n  2134,\n  1110,\n  170,\n  11019,\n  15475,\n  2042,\n  15658,\n  102,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0],\n 'token_type_ids': [0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0],\n 'attention_mask': [1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0]}"},"metadata":{}}]},{"cell_type":"code","source":"# Load model\nmodel = AutoModelForSequenceClassification.from_pretrained(\"bert-base-cased\", num_labels=2)","metadata":{"execution":{"iopub.status.busy":"2023-11-02T13:01:01.672086Z","iopub.execute_input":"2023-11-02T13:01:01.672400Z","iopub.status.idle":"2023-11-02T13:01:05.401846Z","shell.execute_reply.started":"2023-11-02T13:01:01.672375Z","shell.execute_reply":"2023-11-02T13:01:05.400843Z"},"trusted":true},"execution_count":22,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading model.safetensors:   0%|          | 0.00/436M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e8c485b873b84512b7a1f9ed2339a214"}},"metadata":{}},{"name":"stderr","text":"Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}]},{"cell_type":"code","source":"# Set up training arguments\ntraining_args = TrainingArguments(\n    output_dir=\"./sentiment_transfer_learning_transformer/\",          \n    logging_dir='./sentiment_transfer_learning_transformer/logs',            \n    logging_strategy='epoch',\n    logging_steps=100,    \n    num_train_epochs=3,              \n    per_device_train_batch_size=8,  \n    per_device_eval_batch_size=8,  \n    learning_rate=5e-6,\n    seed=42,\n    save_strategy='epoch',\n    save_steps=100,\n    evaluation_strategy='epoch',\n    eval_steps=100,\n    load_best_model_at_end=True\n)","metadata":{"execution":{"iopub.status.busy":"2023-11-02T13:01:05.403338Z","iopub.execute_input":"2023-11-02T13:01:05.404128Z","iopub.status.idle":"2023-11-02T13:01:05.485594Z","shell.execute_reply.started":"2023-11-02T13:01:05.404095Z","shell.execute_reply":"2023-11-02T13:01:05.484600Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"# Number of evaluation modules\nprint(f'There are {len(evaluate.list_evaluation_modules())} evaluation models in Hugging Face.\\n')\n\n# List all evaluation metrics\nevaluate.list_evaluation_modules()","metadata":{"execution":{"iopub.status.busy":"2023-11-02T13:01:05.486883Z","iopub.execute_input":"2023-11-02T13:01:05.487183Z","iopub.status.idle":"2023-11-02T13:01:06.065876Z","shell.execute_reply.started":"2023-11-02T13:01:05.487157Z","shell.execute_reply":"2023-11-02T13:01:06.064848Z"},"trusted":true},"execution_count":24,"outputs":[{"name":"stdout","text":"There are 140 evaluation models in Hugging Face.\n\n","output_type":"stream"},{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"['precision',\n 'code_eval',\n 'roc_auc',\n 'cuad',\n 'xnli',\n 'rouge',\n 'pearsonr',\n 'mse',\n 'super_glue',\n 'comet',\n 'cer',\n 'sacrebleu',\n 'mahalanobis',\n 'wer',\n 'competition_math',\n 'f1',\n 'recall',\n 'coval',\n 'mauve',\n 'xtreme_s',\n 'bleurt',\n 'ter',\n 'accuracy',\n 'exact_match',\n 'indic_glue',\n 'spearmanr',\n 'mae',\n 'squad',\n 'chrf',\n 'glue',\n 'perplexity',\n 'mean_iou',\n 'squad_v2',\n 'meteor',\n 'bleu',\n 'wiki_split',\n 'sari',\n 'frugalscore',\n 'google_bleu',\n 'bertscore',\n 'matthews_correlation',\n 'seqeval',\n 'trec_eval',\n 'rl_reliability',\n 'angelina-wang/directional_bias_amplification',\n 'cpllab/syntaxgym',\n 'kaggle/ai4code',\n 'codeparrot/apps_metric',\n 'mfumanelli/geometric_mean',\n 'poseval',\n 'brier_score',\n 'abidlabs/mean_iou',\n 'abidlabs/mean_iou2',\n 'giulio98/codebleu',\n 'mase',\n 'mape',\n 'smape',\n 'dvitel/codebleu',\n 'NCSOFT/harim_plus',\n 'JP-SystemsX/nDCG',\n 'Drunper/metrica_tesi',\n 'jpxkqx/peak_signal_to_noise_ratio',\n 'jpxkqx/signal_to_reconstruction_error',\n 'hpi-dhc/FairEval',\n 'nist_mt',\n 'lvwerra/accuracy_score',\n 'character',\n 'charcut_mt',\n 'ybelkada/cocoevaluate',\n 'harshhpareek/bertscore',\n 'posicube/mean_reciprocal_rank',\n 'bstrai/classification_report',\n 'omidf/squad_precision_recall',\n 'Josh98/nl2bash_m',\n 'BucketHeadP65/confusion_matrix',\n 'BucketHeadP65/roc_curve',\n 'yonting/average_precision_score',\n 'transZ/test_parascore',\n 'transZ/sbert_cosine',\n 'hynky/sklearn_proxy',\n 'unnati/kendall_tau_distance',\n 'r_squared',\n 'Viona/fuzzy_reordering',\n 'Viona/kendall_tau',\n 'lhy/hamming_loss',\n 'lhy/ranking_loss',\n 'Muennighoff/code_eval_octopack',\n 'yuyijiong/quad_match_score',\n 'Splend1dchan/cosine_similarity',\n 'AlhitawiMohammed22/CER_Hu-Evaluation-Metrics',\n 'Yeshwant123/mcc',\n 'transformersegmentation/segmentation_scores',\n 'sma2023/wil',\n 'chanelcolgate/average_precision',\n 'ckb/unigram',\n 'Felipehonorato/eer',\n 'manueldeprada/beer',\n 'tialaeMceryu/unigram',\n 'He-Xingwei/sari_metric',\n 'langdonholmes/cohen_weighted_kappa',\n 'fschlatt/ner_eval',\n 'hyperml/balanced_accuracy',\n 'brian920128/doc_retrieve_metrics',\n 'guydav/restrictedpython_code_eval',\n 'k4black/codebleu',\n 'Natooz/ece',\n 'ingyu/klue_mrc',\n 'Vipitis/shadermatch',\n 'unitxt/metric',\n 'gabeorlanski/bc_eval',\n 'jjkim0807/code_eval',\n 'vichyt/metric-codebleu',\n 'repllabs/mean_reciprocal_rank',\n 'repllabs/mean_average_precision',\n 'mtc/fragments',\n 'DarrenChensformer/eval_keyphrase',\n 'kedudzic/charmatch',\n 'Vallp/ter',\n 'DarrenChensformer/relation_extraction',\n 'Ikala-allen/relation_extraction',\n 'danieldux/hierarchical_softmax_loss',\n 'nlpln/tst',\n 'bdsaglam/jer',\n 'mcnemar',\n 'exact_match',\n 'wilcoxon',\n 'kaleidophon/almost_stochastic_order',\n 'word_length',\n 'lvwerra/element_count',\n 'word_count',\n 'text_duplicates',\n 'perplexity',\n 'label_distribution',\n 'toxicity',\n 'regard',\n 'honest',\n 'ybelkada/toxicity',\n 'ronaldahmed/ccl_win',\n 'cakiki/tokens_per_byte',\n 'lsy641/distinct']"},"metadata":{}}]},{"cell_type":"code","source":"# Function to compute the metric\ndef compute_metrics(eval_pred):\n    metric = evaluate.load(\"accuracy\")\n    logits, labels = eval_pred\n    # probabilities = tf.nn.softmax(logits)\n    predictions = np.argmax(logits, axis=1)\n    return metric.compute(predictions=predictions, references=labels)","metadata":{"execution":{"iopub.status.busy":"2023-11-02T13:01:06.067115Z","iopub.execute_input":"2023-11-02T13:01:06.067407Z","iopub.status.idle":"2023-11-02T13:01:06.072840Z","shell.execute_reply.started":"2023-11-02T13:01:06.067382Z","shell.execute_reply":"2023-11-02T13:01:06.071833Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"# Train the model\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=dataset_train,\n    eval_dataset=dataset_test,\n    compute_metrics=compute_metrics,\n    callbacks=[EarlyStoppingCallback(early_stopping_patience=1)]\n)\n\ntrainer.train()","metadata":{"execution":{"iopub.status.busy":"2023-11-02T13:01:06.074194Z","iopub.execute_input":"2023-11-02T13:01:06.074501Z","iopub.status.idle":"2023-11-02T13:06:07.057677Z","shell.execute_reply.started":"2023-11-02T13:01:06.074468Z","shell.execute_reply":"2023-11-02T13:06:07.056287Z"},"trusted":true},"execution_count":26,"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"  ········································\n"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01666923236666662, max=1.0)…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"826cc7b97abc4ce5a7fb863c9aee56c4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.15.12 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.15.9"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20231102_130353-bsycczg7</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/anlp_sarcasmdetection/huggingface/runs/bsycczg7' target=\"_blank\">firm-capybara-12</a></strong> to <a href='https://wandb.ai/anlp_sarcasmdetection/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/anlp_sarcasmdetection/huggingface' target=\"_blank\">https://wandb.ai/anlp_sarcasmdetection/huggingface</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/anlp_sarcasmdetection/huggingface/runs/bsycczg7' target=\"_blank\">https://wandb.ai/anlp_sarcasmdetection/huggingface/runs/bsycczg7</a>"},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='434' max='651' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [434/651 01:34 < 00:47, 4.56 it/s, Epoch 2/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.576700</td>\n      <td>0.444897</td>\n      <td>0.857143</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.548200</td>\n      <td>0.448091</td>\n      <td>0.857143</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/4.20k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4713b9efa36548ca9278b55c4b61b08f"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"execution_count":26,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=434, training_loss=0.562465579828359, metrics={'train_runtime': 295.0374, 'train_samples_per_second': 35.263, 'train_steps_per_second': 2.207, 'total_flos': 114058642498560.0, 'train_loss': 0.562465579828359, 'epoch': 2.0})"},"metadata":{}}]},{"cell_type":"code","source":"trainer.evaluate(dataset_test)","metadata":{"execution":{"iopub.status.busy":"2023-11-02T13:06:07.058934Z","iopub.execute_input":"2023-11-02T13:06:07.059217Z","iopub.status.idle":"2023-11-02T13:06:12.843937Z","shell.execute_reply.started":"2023-11-02T13:06:07.059192Z","shell.execute_reply":"2023-11-02T13:06:12.842844Z"},"trusted":true},"execution_count":27,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='88' max='88' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [88/88 00:05]\n    </div>\n    "},"metadata":{}},{"execution_count":27,"output_type":"execute_result","data":{"text/plain":"{'eval_loss': 0.4448966681957245,\n 'eval_accuracy': 0.8571428571428571,\n 'eval_runtime': 5.7726,\n 'eval_samples_per_second': 242.527,\n 'eval_steps_per_second': 15.245,\n 'epoch': 2.0}"},"metadata":{}}]},{"cell_type":"code","source":"# Save tokenizer\ntokenizer.save_pretrained('./sentiment_transfer_learning_transformer_pre/')\n\n# Save model\ntrainer.save_model('./sentiment_transfer_learning_transformer_pre/')","metadata":{"execution":{"iopub.status.busy":"2023-11-02T13:06:12.850398Z","iopub.execute_input":"2023-11-02T13:06:12.851212Z","iopub.status.idle":"2023-11-02T13:06:13.590530Z","shell.execute_reply.started":"2023-11-02T13:06:12.851170Z","shell.execute_reply":"2023-11-02T13:06:13.587466Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}